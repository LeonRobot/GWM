<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of mhmm_em</title>
  <meta name="keywords" content="mhmm_em">
  <meta name="description" content="LEARN_MHMM Compute the ML parameters of an HMM with (mixtures of) Gaussians output using EM.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
  <script type="text/javascript">
    if (top.frames.length == 0) { top.location = "../../index.html"; };
  </script>
</head>
<body>
<a name="_top"></a>
<!-- ../menu.html GridWM --><!-- menu.html mhmm -->
<h1>mhmm_em
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>LEARN_MHMM Compute the ML parameters of an HMM with (mixtures of) Gaussians output using EM.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [LL, prior, transmat, mu, Sigma, mixmat] =mhmm_em(data, prior, transmat, mu, Sigma, mixmat, varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> LEARN_MHMM Compute the ML parameters of an HMM with (mixtures of) Gaussians output using EM.
 [ll_trace, prior, transmat, mu, sigma, mixmat] = learn_mhmm(data, ...
   prior0, transmat0, mu0, sigma0, mixmat0, ...)

 Notation: Q(t) = hidden state, Y(t) = observation, M(t) = mixture variable

 INPUTS:
 data{ex}(:,t) or data(:,t,ex) if all sequences have the same length
 prior(i) = Pr(Q(1) = i),
 transmat(i,j) = Pr(Q(t+1)=j | Q(t)=i)
 mu(:,j,k) = E[Y(t) | Q(t)=j, M(t)=k ]
 Sigma(:,:,j,k) = Cov[Y(t) | Q(t)=j, M(t)=k]
 mixmat(j,k) = Pr(M(t)=k | Q(t)=j) : set to [] or ones(Q,1) if only one mixture component

 Optional parameters may be passed as 'param_name', param_value pairs.
 Parameter names are shown below; default values in [] - if none, argument is mandatory.

 'max_iter' - max number of EM iterations [10]
 'thresh' - convergence threshold [1e-4]
 'verbose' - if 1, print out loglik at every iteration [1]
 'cov_type' - 'full', 'diag' or 'spherical' ['full']

 To clamp some of the parameters, so learning does not change them:
 'adj_prior' - if 0, do not change prior [1]
 'adj_trans' - if 0, do not change transmat [1]
 'adj_mix' - if 0, do not change mixmat [1]
 'adj_mu' - if 0, do not change mu [1]
 'adj_Sigma' - if 0, do not change Sigma [1]

 If the number of mixture components differs depending on Q, just set  the trailing
 entries of mixmat to 0, e.g., 2 components if Q=1, 3 components if Q=2,
 then set mixmat(1,3)=0. In this case, B2(1,3,:)=1.0.</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="fwdbackGamma2.html" class="code" title="function [alpha, beta, gamma, loglik, xi_summed, gamma2] = fwdbackGamma2(init_state_distrib, transmat, obslik, varargin)">fwdbackGamma2</a>	FWDBACK Compute the posterior probs. in an HMM using the forwards backwards algo.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="mhmmFit.html" class="code" title="function [model, loglikHist] = mhmmFit(data, nstates, nmix, varargin)">mhmmFit</a>	function [model, loglikHist] = mhmmFit(data, nstates, nmix, varargin)</li><li><a href="mhmm_em_demo.html" class="code" title="">mhmm_em_demo</a>	</li><li><a href="mhmm_em_demo_orig.html" class="code" title="">mhmm_em_demo_orig</a>	</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [loglik, exp_num_trans, exp_num_visits1, postmix, m, ip, op] =</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [LL, prior, transmat, mu, Sigma, mixmat] = </a><span class="keyword">...</span>
0002     mhmm_em(data, prior, transmat, mu, Sigma, mixmat, varargin)
0003 <span class="comment">% LEARN_MHMM Compute the ML parameters of an HMM with (mixtures of) Gaussians output using EM.</span>
0004 <span class="comment">% [ll_trace, prior, transmat, mu, sigma, mixmat] = learn_mhmm(data, ...</span>
0005 <span class="comment">%   prior0, transmat0, mu0, sigma0, mixmat0, ...)</span>
0006 <span class="comment">%</span>
0007 <span class="comment">% Notation: Q(t) = hidden state, Y(t) = observation, M(t) = mixture variable</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% INPUTS:</span>
0010 <span class="comment">% data{ex}(:,t) or data(:,t,ex) if all sequences have the same length</span>
0011 <span class="comment">% prior(i) = Pr(Q(1) = i),</span>
0012 <span class="comment">% transmat(i,j) = Pr(Q(t+1)=j | Q(t)=i)</span>
0013 <span class="comment">% mu(:,j,k) = E[Y(t) | Q(t)=j, M(t)=k ]</span>
0014 <span class="comment">% Sigma(:,:,j,k) = Cov[Y(t) | Q(t)=j, M(t)=k]</span>
0015 <span class="comment">% mixmat(j,k) = Pr(M(t)=k | Q(t)=j) : set to [] or ones(Q,1) if only one mixture component</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% Optional parameters may be passed as 'param_name', param_value pairs.</span>
0018 <span class="comment">% Parameter names are shown below; default values in [] - if none, argument is mandatory.</span>
0019 <span class="comment">%</span>
0020 <span class="comment">% 'max_iter' - max number of EM iterations [10]</span>
0021 <span class="comment">% 'thresh' - convergence threshold [1e-4]</span>
0022 <span class="comment">% 'verbose' - if 1, print out loglik at every iteration [1]</span>
0023 <span class="comment">% 'cov_type' - 'full', 'diag' or 'spherical' ['full']</span>
0024 <span class="comment">%</span>
0025 <span class="comment">% To clamp some of the parameters, so learning does not change them:</span>
0026 <span class="comment">% 'adj_prior' - if 0, do not change prior [1]</span>
0027 <span class="comment">% 'adj_trans' - if 0, do not change transmat [1]</span>
0028 <span class="comment">% 'adj_mix' - if 0, do not change mixmat [1]</span>
0029 <span class="comment">% 'adj_mu' - if 0, do not change mu [1]</span>
0030 <span class="comment">% 'adj_Sigma' - if 0, do not change Sigma [1]</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% If the number of mixture components differs depending on Q, just set  the trailing</span>
0033 <span class="comment">% entries of mixmat to 0, e.g., 2 components if Q=1, 3 components if Q=2,</span>
0034 <span class="comment">% then set mixmat(1,3)=0. In this case, B2(1,3,:)=1.0.</span>
0035 
0036 <span class="keyword">if</span> ~isempty(varargin) &amp;&amp; ~isstr(varargin{1}) <span class="comment">%#ok&lt;FDEPR&gt; % catch old syntax</span>
0037     error(<span class="string">'optional arguments should be passed as string/value pairs'</span>)
0038 <span class="keyword">end</span>
0039 
0040 [max_iter, thresh, verbose, cov_type,  adj_prior, adj_trans, adj_mix, adj_mu, adj_Sigma] = <span class="keyword">...</span>
0041     process_options(varargin, <span class="string">'max_iter'</span>, 10, <span class="string">'thresh'</span>, 1e-4, <span class="string">'verbose'</span>, 1, <span class="keyword">...</span>
0042     <span class="string">'cov_type'</span>, <span class="string">'full'</span>, <span class="string">'adj_prior'</span>, 1, <span class="string">'adj_trans'</span>, 1, <span class="string">'adj_mix'</span>, 1, <span class="keyword">...</span>
0043     <span class="string">'adj_mu'</span>, 1, <span class="string">'adj_Sigma'</span>, 1);
0044 
0045 previous_loglik = -inf;
0046 loglik = 0;
0047 converged = 0;
0048 num_iter = 1;
0049 LL = [];
0050 
0051 <span class="keyword">if</span> ~iscell(data)
0052     data = num2cell(data, [1 2]); <span class="comment">% each elt of the 3rd dim gets its own cell</span>
0053     <span class="comment">%%%%My edition for supportint mhmmFit</span>
0054 <span class="keyword">elseif</span> length(data)==1
0055     data = num2cell(cell2mat(data), [1 2]); <span class="comment">% each elt of the 3rd dim gets its own cell</span>
0056 <span class="keyword">end</span>
0057 <span class="comment">%numex = length(data);</span>
0058 
0059 
0060 O = size(data{1},1);
0061 Q = length(prior);
0062 <span class="keyword">if</span> isempty(mixmat)
0063     mixmat = ones(Q,1);
0064 <span class="keyword">end</span>
0065 M = size(mixmat,2);     <span class="comment">%here we check if we have define M&gt;1</span>
0066 <span class="keyword">if</span> M == 1               <span class="comment">%so if M==1 we don't look at mixmat values</span>
0067     adj_mix = 0;
0068 <span class="keyword">end</span>
0069 
0070 <span class="keyword">while</span> (num_iter &lt;= max_iter) &amp;&amp; ~converged
0071     <span class="comment">% E step</span>
0072     [loglik, exp_num_trans, exp_num_visits1, postmix, m, ip, op] = <span class="keyword">...</span>
0073         ess_mhmm(prior, transmat, mixmat, mu, Sigma, data);
0074     
0075     
0076     <span class="comment">% M step</span>
0077     <span class="keyword">if</span> adj_prior
0078         prior = normalize(exp_num_visits1);
0079     <span class="keyword">end</span>
0080     <span class="keyword">if</span> adj_trans
0081         transmat = mkStochastic(exp_num_trans);
0082     <span class="keyword">end</span>
0083     <span class="keyword">if</span> adj_mix
0084         mixmat = mkStochastic(postmix);
0085     <span class="keyword">end</span>
0086     <span class="keyword">if</span> adj_mu || adj_Sigma
0087         [mu2, Sigma2] = mixgauss_Mstep(postmix, m, op, ip, <span class="string">'cov_type'</span>, cov_type);
0088         <span class="keyword">if</span> adj_mu
0089             mu = reshape(mu2, [O Q M]);
0090         <span class="keyword">end</span>
0091         <span class="keyword">if</span> adj_Sigma
0092             Sigma = reshape(Sigma2, [O O Q M]);
0093         <span class="keyword">end</span>
0094     <span class="keyword">end</span>
0095     
0096     <span class="keyword">if</span> verbose, fprintf(1, <span class="string">'iteration %d, loglik = %f\n'</span>, num_iter, loglik); <span class="keyword">end</span>
0097     num_iter =  num_iter + 1;
0098     showWarning = true;
0099     converged = convergenceTest(loglik, previous_loglik, thresh,showWarning);
0100     previous_loglik = loglik;
0101     LL = [LL loglik];
0102 <span class="keyword">end</span>
0103 <span class="keyword">end</span>
0104 
0105 <span class="comment">%%%%%%%%%</span>
0106 
0107 <a name="_sub1" href="#_subfunctions" class="code">function [loglik, exp_num_trans, exp_num_visits1, postmix, m, ip, op] = </a><span class="keyword">...</span>
0108     ess_mhmm(prior, transmat, mixmat, mu, Sigma, data)
0109 <span class="comment">% ESS_MHMM Compute the Expected Sufficient Statistics for a MOG Hidden Markov Model.</span>
0110 <span class="comment">%</span>
0111 <span class="comment">% Outputs:</span>
0112 <span class="comment">% exp_num_trans(i,j)   = sum_l sum_{t=2}^T Pr(Q(t-1) = i, Q(t) = j| Obs(l))</span>
0113 <span class="comment">% exp_num_visits1(i)   = sum_l Pr(Q(1)=i | Obs(l))</span>
0114 <span class="comment">%</span>
0115 <span class="comment">% Let w(i,k,t,l) = P(Q(t)=i, M(t)=k | Obs(l))</span>
0116 <span class="comment">% where Obs(l) = Obs(:,:,l) = O_1 .. O_T for sequence l</span>
0117 <span class="comment">% Then</span>
0118 <span class="comment">% postmix(i,k) = sum_l sum_t w(i,k,t,l) (posterior mixing weights/ responsibilities)</span>
0119 <span class="comment">% m(:,i,k)   = sum_l sum_t w(i,k,t,l) * Obs(:,t,l)</span>
0120 <span class="comment">% ip(i,k) = sum_l sum_t w(i,k,t,l) * Obs(:,t,l)' * Obs(:,t,l)</span>
0121 <span class="comment">% op(:,:,i,k) = sum_l sum_t w(i,k,t,l) * Obs(:,t,l) * Obs(:,t,l)'</span>
0122 
0123 
0124 verbose = 0;
0125 
0126 <span class="comment">%[O T numex] = size(data);</span>
0127 numex = length(data);
0128 O = size(data{1},1);
0129 Q = length(prior);
0130 M = size(mixmat,2);
0131 exp_num_trans = zeros(Q,Q);
0132 exp_num_visits1 = zeros(Q,1);
0133 postmix = zeros(Q,M);
0134 m = zeros(O,Q,M);
0135 op = zeros(O,O,Q,M);
0136 ip = zeros(Q,M);
0137 
0138 mix = (M&gt;1);
0139 
0140 loglik = 0;
0141 <span class="keyword">if</span> verbose, fprintf(1, <span class="string">'forwards-backwards example # '</span>); <span class="keyword">end</span>
0142 <span class="keyword">for</span> ex=1:numex
0143     <span class="keyword">if</span> verbose, fprintf(1, <span class="string">'%d '</span>, ex); <span class="keyword">end</span>
0144     <span class="comment">%obs = data(:,:,ex);</span>
0145     obs = data{ex};
0146     T = size(obs,2);
0147     <span class="keyword">if</span> mix
0148         [B, B2] = mixgauss_prob(obs, mu, Sigma, mixmat);
0149         <span class="comment">%[alpha, beta, gamma,  current_loglik, xi_summed, gamma2] = ...</span>
0150         <span class="comment">%fwdback(prior, transmat, B, 'obslik2', B2, 'mixmat', mixmat);</span>
0151         [alpha, beta, gamma,  current_loglik, xi_summed, gamma2] = <span class="keyword">...</span>
0152             <a href="fwdbackGamma2.html" class="code" title="function [alpha, beta, gamma, loglik, xi_summed, gamma2] = fwdbackGamma2(init_state_distrib, transmat, obslik, varargin)">fwdbackGamma2</a>(prior, transmat, B, <span class="string">'obslik2'</span>, B2, <span class="string">'mixmat'</span>, mixmat);
0153     <span class="keyword">else</span> <span class="comment">% we have one gaussian for state</span>
0154         <span class="comment">%% Old style</span>
0155          B = mixgauss_prob(obs, mu, Sigma);
0156 <span class="comment">%         [gamma, alpha, beta, current_loglik] = hmmFwdBack(prior', transmat, B);</span>
0157 <span class="comment">%         xi_summed                   = hmmComputeTwoSliceSum(alpha, beta, transmat,B);</span>
0158         <span class="comment">%% My style</span>
0159 <span class="comment">%         logB = nan(Q,numel(obs));</span>
0160 <span class="comment">%         for j=1:Q</span>
0161 <span class="comment">%             logB(j,:) = gaussLogprob(mu(:, j), Sigma(:, :, j), obs);</span>
0162 <span class="comment">%         end</span>
0163 <span class="comment">%         [logB, scale] = normalizeLogspace(logB');</span>
0164 <span class="comment">%         B             = exp(logB');</span>
0165         <span class="comment">%% Common part</span>
0166         [gamma, alpha, beta, current_loglik] = hmmFwdBack(prior', transmat, B);
0167         xi_summed                   = hmmComputeTwoSliceSum(alpha, beta, transmat,B);
0168         <span class="comment">%%</span>
0169 <span class="comment">%         current_loglik=current_loglik+sum(scale);</span>
0170     <span class="keyword">end</span>
0171     <span class="keyword">if</span> isnan(current_loglik); error(<span class="string">'loglike is NaN (%d)'</span>,ex);<span class="keyword">end</span>;
0172     loglik = loglik +  current_loglik;
0173     <span class="keyword">if</span> verbose, fprintf(1, <span class="string">'ll at ex %d = %f\n'</span>, ex, loglik); <span class="keyword">end</span>
0174     
0175     exp_num_trans = exp_num_trans + xi_summed; <span class="comment">% sum(xi,3);</span>
0176     exp_num_visits1 = exp_num_visits1 + gamma(:,1);
0177     
0178     <span class="keyword">if</span> mix
0179         postmix = postmix + sum(gamma2,3);
0180     <span class="keyword">else</span>
0181         postmix = postmix + sum(gamma,2);
0182         gamma2 = reshape(gamma, [Q 1 T]); <span class="comment">% gamma2(i,m,t) = gamma(i,t)</span>
0183     <span class="keyword">end</span>
0184     <span class="keyword">for</span> i=1:Q
0185         <span class="keyword">for</span> k=1:M
0186             w = reshape(gamma2(i,k,:), [1 T]); <span class="comment">% w(t) = w(i,k,t,l)</span>
0187             wobs = obs .* repmat(w, [O 1]); <span class="comment">% wobs(:,t) = w(t) * obs(:,t)</span>
0188             m(:,i,k) = m(:,i,k) + sum(wobs, 2); <span class="comment">% m(:) = sum_t w(t) obs(:,t)</span>
0189             op(:,:,i,k) = op(:,:,i,k) + wobs * obs'; <span class="comment">% op(:,:) = sum_t w(t) * obs(:,t) * obs(:,t)'</span>
0190             ip(i,k) = ip(i,k) + sum(sum(wobs .* obs, 2)); <span class="comment">% ip = sum_t w(t) * obs(:,t)' * obs(:,t)</span>
0191         <span class="keyword">end</span>
0192     <span class="keyword">end</span>
0193 <span class="keyword">end</span>
0194 <span class="keyword">if</span> verbose, fprintf(1, <span class="string">'\n'</span>); <span class="keyword">end</span>
0195 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Sun 04-Sep-2011 11:01:44 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" target="_parent">m2html</a></strong> &copy; 2005</address>
</body>
</html>